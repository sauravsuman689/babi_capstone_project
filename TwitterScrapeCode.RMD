---
title: "Twitter tweets scraping code"
output:
  word_document: default
  html_notebook: default
---

---
title: "R Notebook"
output: html_notebook
---

```{r}
#install.packages("twitteR")
#install.packages("RCurl")
#install.packages("httr")
#install.packages("syuzhet")
#install.packages("rtweet")
#install.packages("forestmangr")
#install.packages("tidytext")
#install.packages("slam")
library(twitteR)
library(rtweet)
library(RCurl)
library(httr)
library(tm)

```

#### Add you secret token and consumer keys under each variable mentioned below
#### Edit the application name which you created under twitter developers account
```{r}
#setwd("F:/Saurav/Study/GL-Class/Capstone/Sentiment Analysis/twitter_data/project_data")

consumer_key = "xxxxx"
consumer_secret = "xxxxx"
access_token = "xxxxxx"
access_secret ="xxxxx"
application_name = "capstone_pro_senti"

twitter_token <- create_token(app = application_name,consumer_key = consumer_key,consumer_secret = consumer_secret,access_token = access_token,  access_secret = access_secret)

```

#### Edit the movie name in below code to scrape the data of that movie
```{r}

#searchString <- "#LoveAajKal OR #loveaajkal"
#searchString <- "#Baaghi3"

searchString <- "#Tanhaji"

numberOfTweets <- 100000

tweets_data = search_tweets(searchString, n = numberOfTweets, lang = "en", retryonratelimit = TRUE)

```

#### Save the data into a data frame
```{r}

#dabangg3.df <- twListToDF(tweets.df)

tweets.df <- as.data.frame(tweets_data)

```

#### Viw first and last 6 observations of the dataset 
```{r}

head(tweets.df)

tail(tweets.df)

```

#### Write the data into a csv file
```{r}

twitter.movie.df <- data.frame(lapply(tweets.df, as.character), stringsAsFactors=FALSE)


write.csv(twitter.movie.df,"F:/Saurav/Study/GL-Class/Capstone/Sentiment Analysis/twitter_data/project_data/Tanhaji/Tanhaji_set1.csv")

```